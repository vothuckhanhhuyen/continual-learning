# continual_learning

# Continual Learning

1. 2017 - PNAS - EWC - Overcoming catastrophic forgetting in neural networks [[paper]](https://arxiv.org/abs/1612.00796) [[code]](https://github.com/ariseff/overcoming-catastrophic) [[Fisher Information Matrix]](https://agustinus.kristia.de/techblog/2018/03/11/fisher-information/?fbclid=IwAR3VzgUoO2nUXh9KZi39ScHg0HWOyIJ3Ml-5jtnN11YWXXewdclbwisHlQw) [[Natural Gradient Descent]](https://agustinus.kristia.de/techblog/2018/03/14/natural-gradient/) [[On Quadratic Penalties in Elastic Weight Consolidation]](https://arxiv.org/abs/1712.03847)

# Variational Inference

## Week 2
1. 2011 - NIPS - Practical Variational Inference for Neural Networks [[paper]](https://papers.nips.cc/paper/2011/hash/7eb3c8be3d411e8ebfab08eba5f49632-Abstract.html)
2. 2015 - ICML - Weight Uncertainty in Neural Networks [[paper]](https://arxiv.org/abs/1505.05424) [[code]](https://github.com/saxena-mayur/Weight-Uncertainty-in-Neural-Networks) [[code]](https://github.com/nitarshan/bayes-by-backprop/blob/master/Weight%20Uncertainty%20in%20Neural%20Networks.ipynb)
3. 2015 - NIPS - Variational Dropout and the Local Reparameterization Trick [[paper]](https://arxiv.org/abs/1506.02557) 

## Week 3
4. 2017 - ICML - Variational Dropout Sparsifies Deep Neural Networks [[paper]](https://arxiv.org/abs/1701.05369)
5. 2018 - NIPS - Variational Dropout via Empirical Bayes [[paper]](https://arxiv.org/abs/1811.00596)
6. 2019 - CVPR - Variational Bayesian Dropout with a Hierarchical Prior [[paper]](https://arxiv.org/abs/1811.07533)


