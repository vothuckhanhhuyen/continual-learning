# continual_learning

# Continual Learning

### Regularization-based

1. 2017 - PNAS - EWC - Overcoming catastrophic forgetting in neural networks [[paper]](https://arxiv.org/abs/1612.00796) [[code]](https://github.com/ariseff/overcoming-catastrophic) [[Fisher Information Matrix]](https://agustinus.kristia.de/techblog/2018/03/11/fisher-information/?fbclid=IwAR3VzgUoO2nUXh9KZi39ScHg0HWOyIJ3Ml-5jtnN11YWXXewdclbwisHlQw) [[Natural Gradient Descent]](https://agustinus.kristia.de/techblog/2018/03/14/natural-gradient/) [[On Quadratic Penalties in Elastic Weight Consolidation]](https://arxiv.org/abs/1712.03847)
2. 2017 - ICML - SI - Continual Learning Through Synaptic Intelligence [[paper]](https://arxiv.org/abs/1703.04200) [[code]](https://github.com/ganguli-lab/pathint)
3. 2018 - ECCV - MAS - Memory Aware Synapses: Learning what (not) to forget [[paper]](https://arxiv.org/abs/1711.09601) [[code]](https://github.com/wannabeOG/MAS-PyTorch)
4. 2018 - ICLR - VCL - VARIATIONAL CONTINUAL LEARNING [[paper]](https://arxiv.org/abs/1710.10628) [[code]](https://github.com/nvcuong/variational-continual-learning)
5. 2019 - NIPS - UCL - Uncertainty-based Continual Learning with Adaptive Regularization [[paper]](https://arxiv.org/abs/1905.11614) [[code]](https://github.com/csm9493/UCL)
6. 2021 - NIPS - AGS-CL - Continual Learning with Node-Importance based Adaptive Group Sparse Regularization [[paper]](https://arxiv.org/abs/2003.13726)
7. 2016 - ECCV - LwF - Learning without Forgetting [[paper]](https://arxiv.org/abs/1606.09282) [[code]](https://github.com/ngailapdi/LWF)

### Architecture-based

1. 2018 - CVPR - PackNet - PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning [[paper]](https://arxiv.org/abs/1711.05769) [[code]](https://github.com/arunmallya/packnet)
2. 2018 - PMLR - HAT - Overcoming catastrophic forgetting with hard attention to the task [[paper]](https://arxiv.org/abs/1801.01423) [[code]](https://github.com/joansj/hat)
3. 2018 - ICML - SpaceNet - SpaceNet: Make Free Space For Continual Learning [[paper]](https://arxiv.org/abs/1801.01423) [[code]](https://github.com/GhadaSokar/SpaceNet)
4. 2016 - DeepMind - PNN - Progressive Neural Networks [[paper]](https://arxiv.org/abs/1606.04671) [[code]](https://github.com/hengdashi/pnn) [[code]](https://github.com/sumanvid97/progressive_nets_for_multitask_rl)
5. 2018 - ICLR - DEN - Lifelong Learning with Dynamically Expandable Networks [[paper]](https://arxiv.org/abs/1708.01547) [[code]](https://github.com/jaehong31/DEN)
6. 2019 - NIPS - CPG - Compacting, Picking and Growing for Unforgetting Continual Learning [[paper]](https://arxiv.org/abs/1910.06562) [[code]](https://github.com/ivclab/CPG)
7. 2019 - ICML - LtG - Learn to Grow: A Continual Structure Learning Framework for Overcoming Catastrophic Forgetting [[paper]](https://arxiv.org/abs/1904.00310) 
8. 2018 - PiggyBack - Piggyback: Adapting a Single Network to Multiple Tasks by Learning to Mask Weights [[paper]](https://arxiv.org/abs/1801.06519) [[code]](https://github.com/arunmallya/piggyback)

# Variational Inference

## Week 2
1. 2011 - NIPS - Practical Variational Inference for Neural Networks [[paper]](https://papers.nips.cc/paper/2011/hash/7eb3c8be3d411e8ebfab08eba5f49632-Abstract.html)
2. 2015 - ICML - Weight Uncertainty in Neural Networks [[paper]](https://arxiv.org/abs/1505.05424) [[code]](https://github.com/saxena-mayur/Weight-Uncertainty-in-Neural-Networks) [[code]](https://github.com/nitarshan/bayes-by-backprop/blob/master/Weight%20Uncertainty%20in%20Neural%20Networks.ipynb)
3. 2015 - NIPS - Variational Dropout and the Local Reparameterization Trick [[paper]](https://arxiv.org/abs/1506.02557) 

## Week 3
1. 2017 - ICML - Variational Dropout Sparsifies Deep Neural Networks [[paper]](https://arxiv.org/abs/1701.05369) [[code]](https://github.com/bayesgroup/variational-dropout-sparsifies-dnn)
2. 2018 - NIPS - Variational Dropout via Empirical Bayes [[paper]](https://arxiv.org/abs/1811.00596)
3. 2019 - CVPR - Variational Bayesian Dropout with a Hierarchical Prior [[paper]](https://arxiv.org/abs/1811.07533)


# Seminar

1. 2021 - Alleviate Representation Overlapping in Class Incremental Learning by Contrastive Class Concentration [[paper]](https://arxiv.org/abs/2107.12308) 
2. 2021 - ICCV - RECALL: Replay-based Continual Learning in Semantic Segmentation - [[paper]](https://arxiv.org/abs/2108.03673) [[code]](https://github.com/lttm/recall)


